{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spacy_model_extractive.ipynb",
      "provenance": [],
      "mount_file_id": "1BS6Kk7qcP_XFQm7uur3A_dGm9882uWAz",
      "authorship_tag": "ABX9TyO1one7J5FSBYMrSJZO95OJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ACM-Research/NLP-Summarizer/blob/master/Notebooks/SpacyExtractiveModel/spacy_model_extractive_speech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALf6GVTRyGnA",
        "outputId": "a76cb3b6-ebea-4135-d34c-251d73263dac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# credit: https://github.com/Jcharis/Natural-Language-Processing-Tutorials/blob/master/NLP_with_SpaCy/Text%20Summarization%20In%20SpaCy.ipynb\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from string import punctuation\n",
        "import os\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount(\"/content/drive\")\n",
        "#!ls\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxb6Nv_I8Vbz",
        "outputId": "93e850a3-6733-44f2-eed9-8ab583a6e971",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "source": [
        "stopwords = list(STOP_WORDS)\n",
        "#document1 =\"\"\"A flywheel is a mechanical device specifically designed to efficiently store rotational energy (kinetic energy), which is proportional to the square of its rotational speed and its mass. Flywheels resist changes in rotational speed by their moment of inertia and in order to change a flywheel's stored energy (without changing its mass) its rotational speed must be increased or decreased. Since flywheels act as mechanical energy storage devices, they are the kinetic-energy-storage analogue to electrical inductors, for example, which are a type of accumulator. Like other types of accumulators, flywheels smooth the ripple in power output, providing surges of high power output as required, absorbing surges of high power input (system-generated power) as required, and in this way act as low-pass filters on the mechanical velocity (angular, or otherwise) of the system.\"\"\"\n",
        "nlp = spacy.load('en')\n",
        "file_name = input(\"File Name: \")\n",
        "#file_path = os.path.join(\"/content/drive/My Drive/Colab Notebooks/Files/Spacy Model Extractive/corpus\", \"{}.txt\".format(file_name))\n",
        "file_path = os.path.join(\"Dataset/Kaggle Speech Dataset/sotu\", \"{}.txt\".format(file_name))\n",
        "\n",
        "\n",
        "with open(file_path, \"r\") as file:\n",
        "  everything = file.read().replace(\"\\n\", \" \")\n",
        "  \n",
        "  words = everything.split()\n",
        "  docx = nlp(everything)\n",
        "#words"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File Name: Adams_1797\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-20f312e2bb50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0meverything\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Dataset/Kaggle Speech Dataset/sotu/Adams_1797.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VcXS4yS8iTF"
      },
      "source": [
        "mytokens = [token.text for token in docx]\n",
        "mytokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImkFrMq280VN"
      },
      "source": [
        "word_frequencies = {}\n",
        "for word in docx:\n",
        "    if word.text not in stopwords:\n",
        "            if word.text not in word_frequencies.keys():\n",
        "                word_frequencies[word.text] = 1\n",
        "            else:\n",
        "                word_frequencies[word.text] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5PHlajQ83b4"
      },
      "source": [
        "word_frequencies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhCDhDYd87gv"
      },
      "source": [
        "maximum_frequency = max(word_frequencies.values())\n",
        "for word in word_frequencies.keys():  \n",
        "        word_frequencies[word] = (word_frequencies[word]/maximum_frequency)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_a_g1vlMGEk"
      },
      "source": [
        "word_frequencies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhssQqHJMJwz"
      },
      "source": [
        "sentence_list = [ sentence for sentence in docx.sents ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmIgmy77MMCn"
      },
      "source": [
        "[w.text.lower() for t in sentence_list for w in t ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4UFgl4yMP4H"
      },
      "source": [
        "sentence_scores = {}  \n",
        "for sent in sentence_list:  \n",
        "        for word in sent:\n",
        "            if word.text.lower() in word_frequencies.keys():\n",
        "                if len(sent.text.split(' ')) < 30:\n",
        "                    if sent not in sentence_scores.keys():\n",
        "                        sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
        "                    else:\n",
        "                        sentence_scores[sent] += word_frequencies[word.text.lower()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35BPc4fJMtRK"
      },
      "source": [
        "lowered_sentence_list = [w.text.lower() for t in sentence_list for w in t ]\n",
        "lowered_sentence_scores = {}  \n",
        "for sent in lowered_sentence_list:  \n",
        "        for word in sent:\n",
        "            if word in word_frequencies.keys():\n",
        "                if len(sent.split(' ')) < 30:\n",
        "                    if sent not in sentence_scores.keys():\n",
        "                        lowered_sentence_scores[sent] = word_frequencies[word]\n",
        "                    else:\n",
        "                        lowered_sentence_scores[sent] += word_frequencies[word]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLBlyWokM2Gz"
      },
      "source": [
        "sentence_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUoDovDwM9js"
      },
      "source": [
        "from heapq import nlargest\n",
        "summarized_sentences = nlargest(7, sentence_scores, key=sentence_scores.get)\n",
        "summarized_sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbAgbYcjNDEp"
      },
      "source": [
        "for w in summarized_sentences:\n",
        "    print(w.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFNyS1EONF0J"
      },
      "source": [
        "final_sentences = [ w.text for w in summarized_sentences ]\n",
        "summary = ' '.join(final_sentences)\n",
        "summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxp_Cgs5NNkW"
      },
      "source": [
        "len(summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHa6FOp1NQq2"
      },
      "source": [
        "len(words)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}